{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop topic:Text Generation, Summarisation and Prompting\n",
    "\n",
    "### Introduction to Text Generation using GPT-2\n",
    "\n",
    "Text generation stands as one of the most useful applications of Natural Language Processing.\n",
    "Decode based GPT is the still the SOTA of text generation and other NLP tasks. \n",
    "Although we cannot use the latest GPT-4, we are going to use GPT-2, which is a smaller pre-trained model that can be run with limited resources.\n",
    "\n",
    "## Activity 1: GPT-2 Open Text Generation\n",
    "\n",
    "Work on this activity is groups (one at each table)\n",
    "\n",
    "1. Review the following code to understand its working\n",
    "2. Think of a few more prompting examples, and generate texts using them\n",
    "3. Open ChatGPT-3.5 and use the same examples to generate texts\n",
    "4. Compare GPT-2 with GPT-3.5 generation applying human evaluation criteria discussed in Lecture 11. Apply scoring from 1 to 5 for each criteria, add scored together to comare the models.\n",
    "    fluency\n",
    "    coherence / consistency\n",
    "    factuality and correctness\n",
    "    commonsense\n",
    "    style / formality\n",
    "    grammaticality\n",
    "    typicality (what type of something, exemplars etc.)\n",
    "    redundancy\n",
    "5. Discuss your findings in the class. What are the variations between different groups in the class in evaluating texts?\n",
    "\n",
    "**Explanation of code:**\n",
    "\n",
    "    Tokenizer Initialization: The code initializes a GPT-2 tokenizer (tokenizer) to preprocess text inputs. Tokenizers break down input text into tokens, which are numerical representations used by the model.\n",
    "\n",
    "    Model Initialization: The GPT-2 model (model) is loaded. This model is a pre-trained neural network that has learned to predict the next word in a sequence given some context.\n",
    "\n",
    "    Maximum Length: max_length is set to control the length of the generated text. This prevents the model from generating excessively long responses.\n",
    "\n",
    "    Input Prompt: The prompt variable contains the initial snippet of text provided to the model for text generation.\n",
    "\n",
    "    Encoding the Input: The encode() method of the tokenizer converts the input prompt into token IDs (input_ids). These token IDs are the numerical representations of the input text.\n",
    "\n",
    "    Text Generation: The generate() method of the GPT-2 model generates text based on the input token IDs (input_ids). The do_sample=True parameter allows for sampling from the model's predicted probability distribution, adding randomness to the generated text.\n",
    "\n",
    "    Decoding the Output: The decode() method of the tokenizer converts the generated token IDs (output_ids) back into text, excluding any special tokens such as padding or separator tokens.\n",
    "\n",
    "    Printing the Output: The generated text (output_text) is printed to the console for visualization.\n",
    "\n",
    "This code demonstrates the process of using GPT-2 for text generation based on an initial prompt, providing participants with a hands-on understanding of how the model operates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate square root of 2.05 in order to calculate: [1.05 + 2.8 + 0.9] / 2 = 2.0 * 3.9 * 4.9 * 5.9 = 3.3 = 5.0\n",
      "\n",
      "The above equation gives the final solution:\n",
      "\n",
      "Using the current values presented here. Also note that any value greater than 3.9% is considered off by the algorithm and not in the final block chain.\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load the GPT-2 tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Set the maximum length of the generated text\n",
    "max_length = 100\n",
    "\n",
    "# Define the input prompt\n",
    "prompt = \"Calculate square root of 2\"\n",
    "\n",
    "# Encode the input prompt using the tokenizer\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "# Generate the text using the GPT-2 model\n",
    "output_ids = model.generate(input_ids=input_ids, max_length=max_length, do_sample=True)\n",
    "\n",
    "# Decode the generated text using the tokenizer\n",
    "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 2: ChatGPT Prompting\n",
    "\n",
    "Work on this activity in groups (one at each table)\n",
    "\n",
    "### Example of Few Shot Prompting\n",
    "\n",
    "1. Try this example using zero-shot pronpting first. Your prompt would be:\n",
    "\"Convert the following plain English sentence into formal legal language: If you break the rules, you might get kicked out.\"\n",
    "2. Note the response.\n",
    "3. Now enter the following few-shot prompting and compare the response with the zero-shot. Did you get better response?\n",
    "\n",
    "\n",
    "-------- prompt -----------------\n",
    "\n",
    "Convert the following plain English sentences into formal legal language.\n",
    "\n",
    "**Example 1:**  \n",
    "**Input:** You must return the rental car by 5 PM.  \n",
    "**Output:** The renter shall return the vehicle no later than 5:00 PM on the agreed-upon date.\n",
    "\n",
    "**Example 2:**  \n",
    "**Input:** We can cancel the contract if you don't pay on time.  \n",
    "**Output:** The agreement may be terminated by the first party in the event of a failure by the second party to render payment in a timely manner.\n",
    "\n",
    "**Example 3:**  \n",
    "**Input:** You're not allowed to share this document with anyone.  \n",
    "**Output:** Disclosure of this document to any third party is strictly prohibited.\n",
    "\n",
    "**Now your turn:**  \n",
    "**Input:** If you break the rules, you might get kicked out.  \n",
    "**Output:**\n",
    "\n",
    "----------- end of prompt ----------------------\n",
    "\n",
    "4. Now think of a harder example that zero-shot might have trouble with. Try it and note results.\n",
    "\n",
    "Note: Maybe for these relatively simple examples it would not make make much difference, but you got the idea how it works.\n",
    "\n",
    "\n",
    "### Example of Chain-of-Thought Prompting\n",
    "\n",
    "CoT prompting us used for complex reasoning tasks, for example, tasks with many constraints.\n",
    "\n",
    "Here is an example of CoT prompting to solve tasks with contraints. \n",
    "1. First, enter just the last task (scroll down) as zero-shot starting with \"Here is the task for you:\". Note the result. Was the task solved correctly?\n",
    "2. Next enther the following CoT prompt and again, note the result. Did ChatGPT solve your task correctly? Did it follow your example closely? \n",
    "3. Think of another example of possibly harder task (maybe 4 constraints) and follow points 1 and 2.\n",
    "\n",
    "------------- prompt starts here ----------------\n",
    "\n",
    "\n",
    "**Question:**  \n",
    "Three friends — Alice, Bob, and Carol — are sitting in a row of three chairs.  \n",
    "- Alice does not want to sit next to Bob.  \n",
    "- Bob must sit to the left of Carol.  \n",
    "- Carol is not sitting in the middle.\n",
    "\n",
    "Where is everyone sitting?\n",
    "\n",
    "Let's think step by step:\n",
    "\n",
    "1. First, let's list all the possible permutations of the three people:  \n",
    "   ABC, ACB, BAC, BCA, CAB, CBA.\n",
    "\n",
    "2. Now apply the constraint: **Bob must sit to the left of Carol.**  \n",
    "   \n",
    "   For Bob to be to the left of Carol, he must appear **before** Carol in the order.\n",
    "\n",
    "   Let’s check each:\n",
    "   - **ABC** → B is before C (valid)  \n",
    "   - **ACB** → B is after C (invalid  \n",
    "   - **BAC** → B is before C (valid)\n",
    "   - **BCA** → B is before C (valid)\n",
    "   - **CAB** → B is after C (invalid)\n",
    "   - **CBA** → B is after C (invalid) \n",
    "\n",
    "   Valid ones: ABC, BAC, BCA\n",
    "\n",
    "3. Next constraint: **Carol is not in the middle.**\n",
    "\n",
    "   From our remaining options:\n",
    "   - **ABC** → Carol is in position 3 (valid)  \n",
    "   - **BAC** → Carol is in position 3 (valid) \n",
    "   - **BCA** → Carol is in position 2 (invalid) \n",
    "\n",
    "   BCA is eliminated. Remaining: ABC, BAC\n",
    "\n",
    "4. Now apply: **Alice does not want to sit next to Bob.**\n",
    "\n",
    "   - **ABC** → Alice is position 1, Bob is 2 → next to each other (invalid)   \n",
    "   - **BAC** → Bob is 1, Alice is 2 → also next to each other (invalid) \n",
    "\n",
    "Let’s re-express the constraints more carefully:\n",
    "- Alice ≠ adjacent to Bob  \n",
    "- Bob < Carol in position  \n",
    "- Carol ≠ middle seat\n",
    "\n",
    "Try all permutations again but check **all constraints** one by one:\n",
    "\n",
    "| Permutation | Bob < Carol? | Carol ≠ Middle? | Alice ≠ Next to Bob? | Valid? |\n",
    "|-------------|---------------|------------------|------------------------|----------|\n",
    "| ABC         | Yes           | Yes (Carol is 3) | No (Alice next to Bob) | (invalid) |\n",
    "| ACB         | No            | No (Carol is 2)  | Yes                    | (invalid) |\n",
    "| BAC         | Yes           | Yes (Carol is 3) | No                     | (invalid) |\n",
    "| BCA         | Yes           | No (Carol is 2)  | Yes                    | (invalid) |\n",
    "| CAB         | No            | Yes (Carol is 1) | Yes                    | (invalid) |\n",
    "| CBA         | No            | Yes (Carol is 1) | No                     | (invalid) |\n",
    "\n",
    "All are invalid!  \n",
    "So the conclusion is:\n",
    "\n",
    "There is no valid seating arrangement that satisfies all three constraints.\n",
    "\n",
    "Now your turn.\n",
    "\n",
    "Here is the task for you: \n",
    "\n",
    "I have to schedule three meetings in one day: Meeting A, meeting B and meeting C.\n",
    "Meeting A cannot happen before meeting B\n",
    "Meeting C cannot be the first\n",
    "Meeting B Cannot be the last\n",
    "Meetings A and B cannot be scheduled next to each other.\n",
    "\n",
    "Find all possible schedules of these meetings. \n",
    "\n",
    "\n",
    "------------ end of prompt ----------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 3: BART Text Summarisation\n",
    "\n",
    "The following code can summarise text using Bart and trasformer pipeline.\n",
    "\n",
    "1. Review the example code below\n",
    "2. In the second cell of code, implement article summarisation, both abstractive and extractive, from given short news. \n",
    "3. Compare these two types of summarisation using ROUGE, as well as human evaluation as in Activity 2.\n",
    "4. Answer the following questions:\n",
    "    \n",
    "    a. Which type of summarisation generally gives better ROUGE score?\n",
    "    \n",
    "    b. Which type of summarisation generally gives better human score?\n",
    "    \n",
    " Discuss the results in the class. If you find these articles hard to assess the quality of summarisation, you can use some articles from your assignment 2, but need to provide a reference summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in /home/dev/repos/COMP-SCI-7417-Applied-Natural-Language-Processing/.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: six in /home/dev/repos/COMP-SCI-7417-Applied-Natural-Language-Processing/.venv/lib/python3.12/site-packages (from rouge) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n",
      "Your max_length is set to 60, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:  The quick brown fox jumps over the lazy dog. This is a test sentence for summarization. Here is another sentence for testing.\n",
      "Target Summary:  The quick brown fox jumps over the lazy dog. This is a test sentence for summarization.\n",
      "Abstractive Summary:  The quick brown fox jumps over the lazy dog. This is a test sentence for summarization. Here is another sentence for testing. The quick brownfox jumps over a lazy dog to get to the other side of the road. The lazy dog is the one who falls over the quick\n",
      "ROUGE Scores for Abstractive Summary:  [{'rouge-1': {'r': 1.0, 'p': 0.5517241379310345, 'f': 0.7111111065283952}, 'rouge-2': {'r': 1.0, 'p': 0.3488372093023256, 'f': 0.5172413754756243}, 'rouge-l': {'r': 1.0, 'p': 0.5517241379310345, 'f': 0.7111111065283952}}]\n",
      "Extractive Summary:   The quick brown fox jumps over the lazy dog. This is a test sentence for summarization. Here is another sentence for testing. Here are another sentences for summarizing. The test sentence is a short, simple picture of a quick, lazy fox jumping over a lazy dog .\n",
      "ROUGE Scores for Extractive Summary:  [{'rouge-1': {'r': 1.0, 'p': 0.5714285714285714, 'f': 0.7272727226446282}, 'rouge-2': {'r': 1.0, 'p': 0.36585365853658536, 'f': 0.5357142817920919}, 'rouge-l': {'r': 1.0, 'p': 0.5714285714285714, 'f': 0.7272727226446282}}]\n"
     ]
    }
   ],
   "source": [
    "# Text summarisation example\n",
    "\n",
    "!pip install rouge\n",
    "\n",
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers import pipeline\n",
    "from rouge import Rouge\n",
    "\n",
    "# Load the BART tokenizer and model for abstractive summarization\n",
    "tokenizer_abstractive = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model_abstractive = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "# Load the pipeline for extractive summarization\n",
    "pipeline_extractive = pipeline('summarization')\n",
    "\n",
    "# Define the input text\n",
    "input_text = \"The quick brown fox jumps over the lazy dog. This is a test sentence for summarization. Here is another sentence for testing.\"\n",
    "\n",
    "# Define the target summary\n",
    "target_summary = \"The quick brown fox jumps over the lazy dog. This is a test sentence for summarization.\"\n",
    "\n",
    "# Perform abstractive summarization using BART\n",
    "inputs = tokenizer_abstractive([input_text], max_length=1024, truncation=True, padding='max_length', return_tensors='pt')\n",
    "outputs = model_abstractive.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=60, num_beams=4, length_penalty=2.0)\n",
    "summary_abstractive = tokenizer_abstractive.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Perform extractive summarization using pipeline\n",
    "summary_extractive = pipeline_extractive(input_text, max_length=60)[0]['summary_text']\n",
    "\n",
    "# Evaluate the summaries using the ROUGE metric\n",
    "rouge = Rouge()\n",
    "scores_abstractive = rouge.get_scores(summary_abstractive, target_summary)\n",
    "scores_extractive = rouge.get_scores(summary_extractive, target_summary)\n",
    "\n",
    "# Print the summaries and ROUGE scores\n",
    "print(\"Input Text: \", input_text)\n",
    "print(\"Target Summary: \", target_summary)\n",
    "print(\"Abstractive Summary: \", summary_abstractive)\n",
    "print(\"ROUGE Scores for Abstractive Summary: \", scores_abstractive)\n",
    "print(\"Extractive Summary: \", summary_extractive)\n",
    "print(\"ROUGE Scores for Extractive Summary: \", scores_extractive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n",
      "Your max_length is set to 60, but your input_length is only 53. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:  The United States is the third most populous country in the world, with over 330 million people. It is a diverse country, with a wide range of ethnic and cultural backgrounds. The most populous state in the US is California, with over 39 million people.\n",
      "Target Summary:  The United States is the third most populous country in the world.\n",
      "Abstractive Summary:  The United States is the third most populous country in the world, with over 330 million people. It is a diverse country, with a wide range of ethnic and cultural backgrounds. The most populous state in the US is California, withOver 39 million people in the state.\n",
      "ROUGE Scores for Abstractive Summary:  [{'rouge-1': {'r': 0.9090909090909091, 'p': 0.3125, 'f': 0.4651162752623039}, 'rouge-2': {'r': 0.9090909090909091, 'p': 0.23809523809523808, 'f': 0.3773584872766109}, 'rouge-l': {'r': 0.9090909090909091, 'p': 0.3125, 'f': 0.4651162752623039}}]\n",
      "Extractive Summary:   The United States is the third most populous country in the world, with over 330 million people . It is a diverse country, with a wide range of ethnic and cultural backgrounds . The most populous state in the US is California with over 39 million people, the most populous .\n",
      "ROUGE Scores for Extractive Summary:  [{'rouge-1': {'r': 0.9090909090909091, 'p': 0.3125, 'f': 0.4651162752623039}, 'rouge-2': {'r': 0.9090909090909091, 'p': 0.23255813953488372, 'f': 0.37037036712620025}, 'rouge-l': {'r': 0.9090909090909091, 'p': 0.3125, 'f': 0.4651162752623039}}]\n",
      "Input Text:  The Amazon rainforest is the largest tropical rainforest in the world, covering an area of over 6 million square kilometers. It is home to a vast array of plant and animal species, many of which are found nowhere else on Earth. The rainforest is also a vital carbon sink, helping to regulate the Earth's climate.\n",
      "Target Summary:  The Amazon rainforest is the largest tropical rainforest in the world.\n",
      "Abstractive Summary:  The Amazon rainforest is the largest tropical rainforest in the world, covering an area of over 6 million square kilometers. It is home to a vast array of plant and animal species, many of which are found nowhere else on Earth. The rain forest is also a vital carbon sink,\n",
      "ROUGE Scores for Abstractive Summary:  [{'rouge-1': {'r': 0.8888888888888888, 'p': 0.19047619047619047, 'f': 0.31372548728950406}, 'rouge-2': {'r': 0.9, 'p': 0.1836734693877551, 'f': 0.30508474294742893}, 'rouge-l': {'r': 0.8888888888888888, 'p': 0.19047619047619047, 'f': 0.31372548728950406}}]\n",
      "Extractive Summary:   The Amazon rainforest is the largest tropical rainforest in the world, covering an area of over 6 million square kilometers . It is home to a vast array of plant and animal species, many of which are found nowhere else on Earth . Rainforest is also a vital carbon sink, helping\n",
      "ROUGE Scores for Extractive Summary:  [{'rouge-1': {'r': 0.8888888888888888, 'p': 0.19047619047619047, 'f': 0.31372548728950406}, 'rouge-2': {'r': 0.9, 'p': 0.1875, 'f': 0.31034482473246144}, 'rouge-l': {'r': 0.8888888888888888, 'p': 0.19047619047619047, 'f': 0.31372548728950406}}]\n",
      "Input Text:  Water covers over 70% of the Earth's surface, with the majority of it being in the form of saltwater. Freshwater, which is essential for human and animal life, makes up less than 3% of the Earth's total water supply. The largest freshwater lake in the world is Lake Superior, located in North America.\n",
      "Target Summary:  Water covers over 70% of the Earth's surface.\n",
      "Abstractive Summary:  Water covers over 70% of the Earth's surface, with the majority of it being in the form of saltwater. Freshwater, which is essential for human and animal life, makes up less than 3%. The largest freshwater lake in the world is Lake Superior, located in North America\n",
      "ROUGE Scores for Abstractive Summary:  [{'rouge-1': {'r': 0.875, 'p': 0.1794871794871795, 'f': 0.29787233760072435}, 'rouge-2': {'r': 0.8571428571428571, 'p': 0.13333333333333333, 'f': 0.23076922843934913}, 'rouge-l': {'r': 0.875, 'p': 0.1794871794871795, 'f': 0.29787233760072435}}]\n",
      "Extractive Summary:   Water covers over 70% of the Earth's surface, with the majority of it being in the form of saltwater . Freshwater makes up less than 3% of Earth's total water supply . The largest freshwater lake in the world is Lake Superior, located in North America .\n",
      "ROUGE Scores for Extractive Summary:  [{'rouge-1': {'r': 0.875, 'p': 0.2, 'f': 0.32558139232017314}, 'rouge-2': {'r': 0.8571428571428571, 'p': 0.14285714285714285, 'f': 0.2448979567346939}, 'rouge-l': {'r': 0.875, 'p': 0.2, 'f': 0.32558139232017314}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 60, but your input_length is only 56. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:  The European Union is a political and economic union of 27 member states located primarily in Europe. It was formed in the aftermath of World War II with the aim of promoting peace and economic prosperity among its members. The euro is the official currency of 19 of the member states.\n",
      "Target Summary:  The European Union is a political and economic union of 27 member states.\n",
      "Abstractive Summary:  The European Union is a political and economic union of 27 member states located primarily in Europe. It was formed in the aftermath of World War II with the aim of promoting peace and economic prosperity among its members. The euro is the official currency of 19 of the member states.\n",
      "ROUGE Scores for Abstractive Summary:  [{'rouge-1': {'r': 1.0, 'p': 0.35135135135135137, 'f': 0.5199999961520001}, 'rouge-2': {'r': 1.0, 'p': 0.25, 'f': 0.39999999680000003}, 'rouge-l': {'r': 1.0, 'p': 0.35135135135135137, 'f': 0.5199999961520001}}]\n",
      "Extractive Summary:   The European Union is a political and economic union of 27 member states located primarily in Europe . It was formed in the aftermath of World War II with the aim of promoting peace and economic prosperity . The euro is the official currency of 19 of the member states and is the euro .\n",
      "ROUGE Scores for Extractive Summary:  [{'rouge-1': {'r': 1.0, 'p': 0.38235294117647056, 'f': 0.5531914853598914}, 'rouge-2': {'r': 1.0, 'p': 0.25, 'f': 0.39999999680000003}, 'rouge-l': {'r': 1.0, 'p': 0.38235294117647056, 'f': 0.5531914853598914}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 60, but your input_length is only 51. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:  China is the most populous country in the world, with over 1.4 billion people. It is also the second-largest economy in the world, after the United States. The capital of China is Beijing, and the official language is Mandarin.\n",
      "Target Summary:  China is the most populous country in the world.\n",
      "Abstractive Summary:  China is the most populous country in the world, with over 1.4 billion people. The capital of China is Beijing, and the official language is Mandarin. It is also the second-largest economy in the World, after the United States. The country's economy is the second largest\n",
      "ROUGE Scores for Abstractive Summary:  [{'rouge-1': {'r': 0.875, 'p': 0.21212121212121213, 'f': 0.3414634114931589}, 'rouge-2': {'r': 0.875, 'p': 0.16279069767441862, 'f': 0.27450980127643215}, 'rouge-l': {'r': 0.875, 'p': 0.21212121212121213, 'f': 0.3414634114931589}}]\n",
      "Extractive Summary:   China is the most populous country in the world, with over 1.4 billion people . The capital of China is Beijing, and the official language is Mandarin . It is also the second-largest economy in world, after the United States . The official language of the country is Mandarin,\n",
      "ROUGE Scores for Extractive Summary:  [{'rouge-1': {'r': 0.875, 'p': 0.23333333333333334, 'f': 0.36842104930747926}, 'rouge-2': {'r': 0.875, 'p': 0.1590909090909091, 'f': 0.26923076662721895}, 'rouge-l': {'r': 0.875, 'p': 0.23333333333333334, 'f': 0.36842104930747926}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 60, but your input_length is only 58. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:  The human brain is the most complex organ in the body, consisting of over 100 billion neurons and trillions of connections between them. It controls everything we do, from our thoughts and emotions to our movements and senses. The brain is divided into different regions that are responsible for different functions.\n",
      "Target Summary:  The human brain is the most complex organ in the body.\n",
      "Abstractive Summary:  The human brain is the most complex organ in the body, consisting of over 100 billion neurons and trillions of connections between them. It controls everything we do, from our thoughts and emotions to our movements and senses. The brain is divided into different regions that are responsible for different functions.\n",
      "ROUGE Scores for Abstractive Summary:  [{'rouge-1': {'r': 0.9, 'p': 0.21428571428571427, 'f': 0.34615384304733726}, 'rouge-2': {'r': 0.9, 'p': 0.1836734693877551, 'f': 0.30508474294742893}, 'rouge-l': {'r': 0.9, 'p': 0.21428571428571427, 'f': 0.34615384304733726}}]\n",
      "Extractive Summary:   The human brain is the most complex organ in the body, consisting of over 100 billion neurons and trillions of connections between them . It controls everything we do, from our thoughts and emotions to our movements and senses . The brain is divided into different regions that are responsible for different functions .\n",
      "ROUGE Scores for Extractive Summary:  [{'rouge-1': {'r': 0.9, 'p': 0.21428571428571427, 'f': 0.34615384304733726}, 'rouge-2': {'r': 0.9, 'p': 0.1836734693877551, 'f': 0.30508474294742893}, 'rouge-l': {'r': 0.9, 'p': 0.21428571428571427, 'f': 0.34615384304733726}}]\n",
      "Input Text:  The Great Barrier Reef is the largest coral reef system in the world, stretching over 2,300 kilometers along the coast of Australia. It is home to thousands of species of marine life, including sea turtles, dolphins, and sharks. The reef is under threat from climate change and other environmental factors.\n",
      "Target Summary:  The Great Barrier Reef is the largest coral reef system in the world.\n",
      "Abstractive Summary:  The Great Barrier Reef is the largest coral reef system in the world, stretching over 2,300 kilometers along the coast of Australia. It is home to thousands of species of marine life, including sea turtles, dolphins, and sharks. The reef is under threat from climate change and other environmental\n",
      "ROUGE Scores for Abstractive Summary:  [{'rouge-1': {'r': 0.9166666666666666, 'p': 0.275, 'f': 0.42307691952662724}, 'rouge-2': {'r': 0.9166666666666666, 'p': 0.22916666666666666, 'f': 0.3666666634666667}, 'rouge-l': {'r': 0.9166666666666666, 'p': 0.275, 'f': 0.42307691952662724}}]\n",
      "Extractive Summary:   The Great Barrier Reef is the largest coral reef system in the world, stretching over 2,300 kilometers along the coast of Australia . It is home to thousands of species of marine life, including sea turtles, dolphins, and sharks . The reef is under threat from climate change and other environmental\n",
      "ROUGE Scores for Extractive Summary:  [{'rouge-1': {'r': 0.9166666666666666, 'p': 0.275, 'f': 0.42307691952662724}, 'rouge-2': {'r': 0.9166666666666666, 'p': 0.22916666666666666, 'f': 0.3666666634666667}, 'rouge-l': {'r': 0.9166666666666666, 'p': 0.275, 'f': 0.42307691952662724}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 60, but your input_length is only 57. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:  The International Space Station (ISS) is a habitable artificial satellite that orbits the Earth. It is a joint project between five space agencies, including NASA, Roscosmos, and the European Space Agency. The ISS is used for scientific research, space exploration, and international cooperation.\n",
      "Target Summary:  The International Space Station (ISS) is a habitable artificial satellite that orbits the Earth.\n",
      "Abstractive Summary:  The International Space Station (ISS) is a habitable artificial satellite that orbits the Earth. It is a joint project between five space agencies, including NASA, Roscosmos, and the European Space Agency. The ISS is used for scientific research, space exploration, and international cooperation.\n",
      "ROUGE Scores for Abstractive Summary:  [{'rouge-1': {'r': 1.0, 'p': 0.4, 'f': 0.5714285673469389}, 'rouge-2': {'r': 1.0, 'p': 0.3170731707317073, 'f': 0.48148147782578876}, 'rouge-l': {'r': 1.0, 'p': 0.4, 'f': 0.5714285673469389}}]\n",
      "Extractive Summary:   The International Space Station (ISS) is a habitable artificial satellite that orbits the Earth . It is a joint project between NASA, Roscosmos, and the European Space Agency . The ISS is used for scientific research, space exploration, and international cooperation . The station is used by five space\n",
      "ROUGE Scores for Extractive Summary:  [{'rouge-1': {'r': 1.0, 'p': 0.4, 'f': 0.5714285673469389}, 'rouge-2': {'r': 1.0, 'p': 0.3023255813953488, 'f': 0.46428571072066327}, 'rouge-l': {'r': 1.0, 'p': 0.4, 'f': 0.5714285673469389}}]\n",
      "Input Text:  The African elephant is the largest land animal in the world, weighing up to 6,000 kilograms and standing over three meters tall. It is found in 37 countries in sub-Saharan Africa and is known for its distinctive trunk and large, floppy ears. The elephant is under threat from habitat loss and poaching.\n",
      "Target Summary:  The African elephant is the largest land animal in the world.\n",
      "Abstractive Summary:  The African elephant is the largest land animal in the world, weighing up to 6,000 kilograms and standing over three meters tall. It is found in 37 countries in sub-Saharan Africa and is known for its distinctive trunk and large, floppy ears. The elephant is under threat from habitat\n",
      "ROUGE Scores for Abstractive Summary:  [{'rouge-1': {'r': 0.9, 'p': 0.23076923076923078, 'f': 0.36734693552686387}, 'rouge-2': {'r': 0.9, 'p': 0.19148936170212766, 'f': 0.31578947079101266}, 'rouge-l': {'r': 0.9, 'p': 0.23076923076923078, 'f': 0.36734693552686387}}]\n",
      "Extractive Summary:   The African elephant is the largest land animal in the world weighing up to 6,000 kilograms and standing over three meters tall . It is found in 37 countries in sub-Saharan Africa and is known for its distinctive trunk and large, floppy ears . The elephant is under threat from habitat loss\n",
      "ROUGE Scores for Extractive Summary:  [{'rouge-1': {'r': 1.0, 'p': 0.25, 'f': 0.39999999680000003}, 'rouge-2': {'r': 1.0, 'p': 0.20833333333333334, 'f': 0.3448275833531511}, 'rouge-l': {'r': 1.0, 'p': 0.25, 'f': 0.39999999680000003}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 60, but your input_length is only 54. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:  The Eiffel Tower is an iconic landmark in Paris, France, and one of the most recognizable structures in the world. It was built for the 1889 World's Fair and stands over 300 meters tall. The tower is visited by millions of tourists every year.\n",
      "Target Summary:  The Eiffel Tower is an iconic landmark in Paris, France.\n",
      "Abstractive Summary:  The Eiffel Tower is an iconic landmark in Paris, France. It was built for the 1889 World's Fair and stands over 300 meters tall. The tower is visited by millions of tourists every year. It is one of the most recognizable structures in the world, and is a UNESCO\n",
      "ROUGE Scores for Abstractive Summary:  [{'rouge-1': {'r': 1.0, 'p': 0.2564102564102564, 'f': 0.40816326205747605}, 'rouge-2': {'r': 1.0, 'p': 0.1875, 'f': 0.31578947102493077}, 'rouge-l': {'r': 1.0, 'p': 0.2564102564102564, 'f': 0.40816326205747605}}]\n",
      "Extractive Summary:   The Eiffel Tower is one of the most recognizable structures in the world . It was built for the 1889 World's Fair and stands over 300 meters tall . The tower is visited by millions of tourists every year and is a major tourist attraction in Paris . It is the tallest building in\n",
      "ROUGE Scores for Extractive Summary:  [{'rouge-1': {'r': 0.5, 'p': 0.1282051282051282, 'f': 0.20408162940441485}, 'rouge-2': {'r': 0.3333333333333333, 'p': 0.06, 'f': 0.1016949126687734}, 'rouge-l': {'r': 0.5, 'p': 0.1282051282051282, 'f': 0.20408162940441485}}]\n"
     ]
    }
   ],
   "source": [
    "# Text summarisation example\n",
    "\n",
    "# !pip install rouge\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers import pipeline\n",
    "from rouge import Rouge\n",
    "\n",
    "# Load the CNN/DailyMail dataset\n",
    "df = pd.read_csv('./daily_cnn.csv')\n",
    "\n",
    "# Load the BART tokenizer and model for abstractive summarization\n",
    "tokenizer_abstractive = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model_abstractive = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "# Load the pipeline for extractive summarization\n",
    "pipeline_extractive = pipeline('summarization')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Extract the article and the reference summary\n",
    "    input_text = row['article']\n",
    "    target_summary = row['highlights']\n",
    "\n",
    "    # Perform abstractive summarization using BART\n",
    "    inputs = tokenizer_abstractive([input_text], max_length=1024, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    outputs = model_abstractive.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=60, num_beams=4, length_penalty=2.0)\n",
    "    summary_abstractive = tokenizer_abstractive.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Perform extractive summarization using pipeline\n",
    "    summary_extractive = pipeline_extractive(input_text, max_length=60)[0]['summary_text']\n",
    "\n",
    "    # Evaluate the summaries using the ROUGE metric\n",
    "    rouge = Rouge()\n",
    "    scores_abstractive = rouge.get_scores(summary_abstractive, target_summary)\n",
    "    scores_extractive = rouge.get_scores(summary_extractive, target_summary)\n",
    "\n",
    "    # Print the summaries and ROUGE scores\n",
    "    print(\"Input Text: \", input_text)\n",
    "    print(\"Target Summary: \", target_summary)\n",
    "    print(\"Abstractive Summary: \", summary_abstractive)\n",
    "    print(\"ROUGE Scores for Abstractive Summary: \", scores_abstractive)\n",
    "    print(\"Extractive Summary: \", summary_extractive)\n",
    "    print(\"ROUGE Scores for Extractive Summary: \", scores_extractive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
